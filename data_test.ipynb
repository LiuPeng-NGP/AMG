{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "class MP3Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.mp3')]\n",
    "        self.sample_rate = 24000  # Assuming all MP3 files are sampled at 24kHz\n",
    "        self.sequence_length = 1024\n",
    "        self.embedding_dim = 1024\n",
    "        self.desired_samples = math.floor(self.sequence_length * self.embedding_dim / 2) # 2 stand for channels, because we need to flatten channels\n",
    "        self.current_index = 0\n",
    "        self.prefetch_buffer = 4  # Number of batches to prefetch\n",
    "        self.prefetch_data = [None] * self.prefetch_buffer\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get the next batch from the prefetch buffer\n",
    "        if self.current_index >= len(self.file_list):\n",
    "            self.current_index = 0\n",
    "\n",
    "        batch_data = self.prefetch_data[self.current_index % self.prefetch_buffer]\n",
    "        self.current_index += 1\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    def prefetch(self):\n",
    "        for i in range(self.prefetch_buffer):\n",
    "            idx = (self.current_index + i) % len(self.file_list)\n",
    "            file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
    "            waveform, sample_rate = torchaudio.load(file_path, format='mp3')\n",
    "            waveform_cut_normalized_reshaped = self.transform(waveform)\n",
    "            self.prefetch_data[i] = waveform_cut_normalized_reshaped\n",
    "\n",
    "    def transform(self, waveform):\n",
    "        max_start_position = max(0, waveform.shape[1] - self.desired_samples)\n",
    "        if max_start_position == 0:\n",
    "            padding = torch.zeros(self.desired_samples - waveform.shape[1], dtype=waveform.dtype)\n",
    "            padding_expanded = padding.view(1, -1).expand(waveform.shape[0], self.desired_samples - waveform.shape[1])\n",
    "            waveform_padded = torch.cat((waveform, padding_expanded), dim=1)\n",
    "            waveform_cut_permuted = waveform_padded.permute(1, 0)\n",
    "        else:\n",
    "            # Choose a random start position\n",
    "            cut_position = random.randint(0, max_start_position)\n",
    "\n",
    "            # Cut and permute dimensions\n",
    "            waveform_cut = waveform[:, cut_position:cut_position + self.desired_samples]\n",
    "            waveform_cut_permuted = waveform_cut.permute(1, 0)\n",
    "            \n",
    "        codes_cut_normalized_reshaped = waveform_cut_permuted.contiguous().view(self.sequence_length, -1)\n",
    "\n",
    "        return codes_cut_normalized_reshaped\n",
    "    \n",
    "\n",
    "def get_mp3_file(generated_codes: torch.Tensor, \n",
    "                    filename,\n",
    "                    sample_rate = 24000,\n",
    "                    ):\n",
    "\n",
    "    generated_codes_review = generated_codes.contiguous().view(-1, 2)\n",
    "    generated_codes_permuted = generated_codes_review.permute(1, 0)\n",
    "    # Move the tensor to the CPU\n",
    "    generated_codes_permuted = generated_codes_permuted.cpu()\n",
    "    torchaudio.save(filename, generated_codes_permuted, sample_rate, format='mp3')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=MP3Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating mean and std: 100%|██████████| 7235/7235 [1:14:57<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -7.885345257818699e-05, Std: 0.04968889430165291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = \"mp3s\"\n",
    "\n",
    "def calculate_mean_std(root_dir):\n",
    "    mean_sum = 0\n",
    "    std_sum = 0\n",
    "    total_samples = 0\n",
    "    file_list = [f for f in os.listdir(root_dir) if f.endswith('.mp3')]\n",
    "\n",
    "    for file_name in tqdm(file_list, desc=\"Calculating mean and std\"):\n",
    "        file_path = os.path.join(root_dir, file_name)\n",
    "        waveform, sample_rate = torchaudio.load(file_path, format='mp3')\n",
    "        waveform = waveform.reshape(-1)  # Flatten the waveform using reshape\n",
    "        mean_sum += waveform.mean()\n",
    "        std_sum += waveform.std()\n",
    "        total_samples += waveform.numel()\n",
    "\n",
    "    mean = mean_sum / len(file_list)\n",
    "    std = std_sum / len(file_list)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "mean, std = calculate_mean_std(root_dir=root_dir)\n",
    "print(f\"Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "class MP3Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.mp3')]\n",
    "        self.sample_rate = 24000  # Assuming all MP3 files are sampled at 24kHz\n",
    "        self.sequence_length = 1024\n",
    "        self.embedding_dim = 1024\n",
    "        self.desired_samples = math.floor(self.sequence_length * self.embedding_dim / 2) # 2 stand for channels, because we need to flatten channels\n",
    "        self.current_index = 0\n",
    "        self.prefetch_buffer = 4  # Number of batches to prefetch\n",
    "        self.prefetch_data = [None] * self.prefetch_buffer\n",
    "        self.audio_mean = -7.885345257818699e-05\n",
    "        self.audio_var = 0.04968889430165291\n",
    "        self.tar_mean = 0\n",
    "        self.tar_var = 1\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get the next batch from the prefetch buffer\n",
    "        if self.current_index >= len(self.file_list):\n",
    "            self.current_index = 0\n",
    "\n",
    "        batch_data = self.prefetch_data[self.current_index % self.prefetch_buffer]\n",
    "        self.current_index += 1\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    def prefetch(self):\n",
    "        for i in range(self.prefetch_buffer):\n",
    "            idx = (self.current_index + i) % len(self.file_list)\n",
    "            file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
    "            waveform, sample_rate = torchaudio.load(file_path, format='mp3')\n",
    "            waveform_cut_normalized_reshaped = self.transform(waveform)\n",
    "            self.prefetch_data[i] = waveform_cut_normalized_reshaped\n",
    "\n",
    "    def transform(self, waveform):\n",
    "        max_start_position = max(0, waveform.shape[1] - self.desired_samples)\n",
    "        if max_start_position == 0:\n",
    "            padding = torch.zeros(self.desired_samples - waveform.shape[1], dtype=waveform.dtype)\n",
    "            padding_expanded = padding.view(1, -1).expand(waveform.shape[0], self.desired_samples - waveform.shape[1])\n",
    "            waveform_padded = torch.cat((waveform, padding_expanded), dim=1)\n",
    "            waveform_cut_permuted = waveform_padded.permute(1, 0)\n",
    "        else:\n",
    "            # Choose a random start position\n",
    "            cut_position = random.randint(0, max_start_position)\n",
    "\n",
    "            # Cut and permute dimensions\n",
    "            waveform_cut = waveform[:, cut_position:cut_position + self.desired_samples]\n",
    "            waveform_cut_permuted = waveform_cut.permute(1, 0)\n",
    "            \n",
    "        codes_cut_normalized_reshaped = waveform_cut_permuted.contiguous().view(self.sequence_length, -1)\n",
    "        codes_normalized = self.tar_var * (codes_cut_normalized_reshaped - self.audio_mean)/self.audio_var + self.tar_mean\n",
    "\n",
    "        return codes_normalized\n",
    "    \n",
    "\n",
    "def get_mp3_file(generated_codes: torch.Tensor, \n",
    "                    save_path,\n",
    "                    sample_rate = 24000,\n",
    "                    ):\n",
    "    \n",
    "    audio_mean = -7.885345257818699e-05\n",
    "    audio_var = 0.04968889430165291\n",
    "    tar_mean = 0\n",
    "    tar_var = 1\n",
    "    unnormalized_code = torch.clamp(audio_var * (generated_codes-tar_mean)/tar_var + audio_mean, -1,1)\n",
    "    generated_codes_review = unnormalized_code.contiguous().view(-1, 2)\n",
    "    generated_codes_permuted = generated_codes_review.permute(1, 0)\n",
    "    # Move the tensor to the CPU\n",
    "    generated_codes_permuted = generated_codes_permuted.cpu()\n",
    "    torchaudio.save(save_path, generated_codes_permuted, sample_rate, format='mp3')\n",
    "    return\n",
    "\n",
    "dataset = MP3Dataset(root_dir = \"mp3s\")\n",
    "dataset.prefetch()\n",
    "\n",
    "tmp = dataset[0]\n",
    "print(tmp.shape)\n",
    "get_mp3_file(tmp,'test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
